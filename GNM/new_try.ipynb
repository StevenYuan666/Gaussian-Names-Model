{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Set Seed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "def set_seed(seed):\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Text Encoder Decoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from mup import MuReadout, MuSharedReadout\n",
    "from positional_encodings import PositionalEncoding\n",
    "from transformer import TransformerDecoder, TransformerEncoder\n",
    "from functools import cache\n",
    "\n",
    "\n",
    "def shift_right(input_ids, inplace=True):\n",
    "    decoder_start_token_id = 0\n",
    "\n",
    "    if not inplace:\n",
    "        shifted_input_ids = input_ids.clone()\n",
    "    else:\n",
    "        shifted_input_ids = input_ids\n",
    "\n",
    "    shifted_input_ids[:, 1:] = input_ids[:, :-1]\n",
    "    shifted_input_ids[:, 0] = decoder_start_token_id\n",
    "    return shifted_input_ids\n",
    "\n",
    "\n",
    "class TextModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            config: dict,\n",
    "    ):\n",
    "        \"\"\"Module for text fields, includes both an encoder and a decoder.\n",
    "\n",
    "        Args:\n",
    "            config (dict): Configuration dictionary. Must contain the following keys:\n",
    "                - text_model: \"custom\" or \"t5-small\"\n",
    "                - vocab_size: Size of the vocabulary\n",
    "                - d_model: Dimension of the model\n",
    "                - dropout: Dropout rate\n",
    "                - nhead: Number of attention heads\n",
    "                - num_layers: Number of layers\n",
    "                - d_ff_mult: Multiplier for the feedforward dimension (d_ff = d_ff_mult * d_model)\n",
    "                - text_encoder_layers: Number of layers in the encoder\n",
    "                - text_decoder_layers: Number of layers in the decoder\n",
    "                - freeze: Whether to freeze the parameters of the T5 model\n",
    "                - sparse_embedding: Whether to use sparse embeddings\n",
    "\n",
    "        Raises:\n",
    "            NotImplementedError: If text_model is not \"custom\" or \"t5-small\".\n",
    "\n",
    "        Returns:\n",
    "            TextModule\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if config[\"text_model\"] == \"custom\":\n",
    "            self.input_embedding = nn.Embedding(\n",
    "                config[\"vocab_size\"],\n",
    "                config[\"d_model\"],\n",
    "            )\n",
    "            self.pe = PositionalEncoding(\n",
    "                config[\"d_model\"], config[\"dropout\"], max_len=2048\n",
    "            )\n",
    "            self.encoder = TextEncoder(\n",
    "                config,\n",
    "                config[\"text_encoder_layers\"],\n",
    "                self.input_embedding,\n",
    "                self.pe,\n",
    "            )\n",
    "            self.decoder = TextDecoder(\n",
    "                config,\n",
    "                num_layers=config[\"text_decoder_layers\"],\n",
    "                embedding=self.input_embedding,\n",
    "                pe=self.pe,\n",
    "            )\n",
    "        elif config[\"text_model\"] == \"t5-small\":\n",
    "            from transformers import T5ForConditionalGeneration  # type: ignore\n",
    "\n",
    "            self.model = T5ForConditionalGeneration.from_pretrained(  # type: ignore\n",
    "                \"t5-small\",\n",
    "            )\n",
    "\n",
    "            self.encoder = self.model.encoder  # type: ignore\n",
    "\n",
    "            class LMHeadDecoder(nn.Module):\n",
    "                def __init__(self, model):\n",
    "                    super().__init__()\n",
    "                    self.decoder = model.decoder\n",
    "                    self.lm_head = model.lm_head\n",
    "                    self.scale = model.model_dim ** -0.5\n",
    "\n",
    "                def forward(self, **kwargs):\n",
    "                    x = self.decoder(**kwargs).last_hidden_state\n",
    "                    x = self.lm_head(x * self.scale)\n",
    "                    return x\n",
    "\n",
    "            self.decoder = LMHeadDecoder(self.model)  # type: ignore\n",
    "            self.input_embedding = self.model.get_input_embeddings()  # type: ignore\n",
    "            if config[\"freeze\"]:\n",
    "                print(\"Freezing T5 parameters\")\n",
    "                for param in self.parameters():  # type: ignore\n",
    "                    param.requires_grad = False\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def _shift_right(self, input_ids, inplace=False):\n",
    "        return shift_right(input_ids, inplace=inplace)\n",
    "\n",
    "    def zero_pad(self, pad_token_id):\n",
    "        self.encoder.embedding.weight.data[pad_token_id] = 0  # type: ignore\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, config, num_layers=None, embedding=None, pe=None, pe_len=None):\n",
    "        super().__init__()\n",
    "        if num_layers is None:\n",
    "            num_layers = config[\"num_layers\"]\n",
    "        self.encoder = TransformerEncoder(\n",
    "            d_model=config[\"d_model\"],\n",
    "            dropout=config[\"dropout\"],\n",
    "            nhead=config[\"nhead\"],\n",
    "            dim_feedforward=config[\"d_model\"] * [\"d_ff_mult\"],\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.positional_encoding = (\n",
    "            pe\n",
    "            if pe is not None\n",
    "            else PositionalEncoding(\n",
    "                config[\"d_model\"],\n",
    "                config[\"dropout\"],\n",
    "                max_len=pe_len,\n",
    "            )\n",
    "        )\n",
    "        self.embedding = (\n",
    "            embedding\n",
    "            if embedding is not None\n",
    "            else nn.Embedding(\n",
    "                config[\"vocab_size\"],\n",
    "                config[\"d_model\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if config[\"encoder_readout\"] == \"tied\":\n",
    "            self.readout = LMHead(config, self.embedding)\n",
    "        elif config[\"encoder_readout\"] == \"separate\":\n",
    "            self.readout = LMHead(config)\n",
    "        elif config[\"encoder_readout\"] == \"none\":\n",
    "            self.readout = lambda x: x\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self._zero_pad(config[\"categorical_pad_token_id\"])\n",
    "\n",
    "    def _zero_pad(self, pad_token_id):\n",
    "        self.embedding.weight.data[pad_token_id] = 0\n",
    "\n",
    "    def _shift_right(self, input_ids, inplace=False):\n",
    "        return shift_right(input_ids, inplace=inplace)\n",
    "\n",
    "    def _causal_mask_like(self, x):\n",
    "        @cache\n",
    "        def cached_call(sz, device):\n",
    "            return torch.nn.Transformer.generate_square_subsequent_mask(sz, device)\n",
    "\n",
    "        return cached_call(x.shape[1], x.device)\n",
    "\n",
    "    def encode(\n",
    "            self, x, attention_mask=None, padding_mask=None, is_causal=False, shift_right=False\n",
    "    ):\n",
    "        \"\"\"Encode a sequence of tokens.\n",
    "        Args:\n",
    "            x (Tensor): Input tokens of shape (batch_size, seq_len).\n",
    "            attention_mask (Tensor, optional): Square mask of shape (seq_len, seq_len). Defaults to None.\n",
    "            padding_mask (Tensor, optional): Padding mask of shape (batch_size, seq_len).\n",
    "                Used for key masking. Defaults to None.\n",
    "            is_causal (bool, optional): Whether to use a causal mask. This would override the mask\n",
    "                argument when True. Defaults to False.\n",
    "            shift_right (bool, optional): Whether to shift the input sequence to the right by one.\n",
    "                The first token is set to 0. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Encoded sequence of shape (batch_size, seq_len, d_output). d_output is either\n",
    "                d_model or vocab_size depending on the readout layer.\n",
    "        \"\"\"\n",
    "        if is_causal:\n",
    "            if attention_mask is not None:\n",
    "                raise ValueError(\"Cannot use both attention_mask and is_causal\")\n",
    "            attention_mask = self._causal_mask_like(x)\n",
    "        if shift_right:\n",
    "            x = self._shift_right(x)\n",
    "            if padding_mask is not None:\n",
    "                padding_mask = self._shift_right(padding_mask)\n",
    "            if not is_causal and attention_mask is not None:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "        x = self(x, attention_mask, padding_mask, is_causal=is_causal)\n",
    "        x = self.readout(x)\n",
    "        # Standardize the output shape\n",
    "        x = nn.Sigmoid()(x, dim=-1)\n",
    "        return x\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            src,\n",
    "            attention_mask=None,\n",
    "            padding_mask=None,\n",
    "            is_causal=False,\n",
    "    ):\n",
    "        src = self.embedding(src)\n",
    "        src = self.positional_encoding(src)\n",
    "        src = self.encoder(\n",
    "            src,\n",
    "            attention_mask,\n",
    "            padding_mask,\n",
    "            is_causal=is_causal,\n",
    "        )\n",
    "        return src\n",
    "\n",
    "\n",
    "class TextDecoder(nn.Module):\n",
    "    def __init__(self, config, num_layers=None, embedding=None, pe=None, causal=True):\n",
    "        super().__init__()\n",
    "        if num_layers is None:\n",
    "            num_layers = config[\"num_layers\"]\n",
    "        self.decoder = TransformerDecoder(\n",
    "            d_model=config[\"d_model\"],\n",
    "            dropout=config[\"dropout\"],\n",
    "            nhead=config[\"nhead\"],\n",
    "            dim_feedforward=config[\"d_model\"] * 4,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.emmbedding = embedding\n",
    "        self.readout = LMHead(config, embedding)\n",
    "\n",
    "        if pe is None:\n",
    "            self.positional_encoding = PositionalEncoding(\n",
    "                config[\"d_model\"],\n",
    "                config[\"dropout\"],\n",
    "            )\n",
    "        else:\n",
    "            self.positional_encoding = pe\n",
    "        self.causal = causal\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids,\n",
    "            encoder_hidden_states,\n",
    "            memory_mask=None,\n",
    "            attention_mask=None,\n",
    "            memory_key_padding_mask=None,\n",
    "    ):\n",
    "        if self.emmbedding is not None:\n",
    "            x = self.emmbedding(input_ids)\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                \"Need to implement passing embeddings directly to decoder\"\n",
    "            )\n",
    "        tgt_mask = self._causal_mask(x.shape[1], x.device) if self.causal else None\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.decoder(\n",
    "            x,\n",
    "            encoder_hidden_states,\n",
    "            tgt_mask,\n",
    "            memory_mask,\n",
    "            attention_mask,\n",
    "            memory_key_padding_mask,\n",
    "        )\n",
    "        x = self.readout(x)\n",
    "        return x\n",
    "\n",
    "    def _causal_mask(self, size, device=None):\n",
    "        # TODO does caching help here?\n",
    "        mask = torch.full((size, size), float(\"-inf\"), device=device)\n",
    "        mask.triu_(diagonal=1)\n",
    "        return mask\n",
    "\n",
    "\n",
    "class LMHead(nn.Module):\n",
    "    def __init__(self, config, embedding=None):\n",
    "        super().__init__()\n",
    "        use_mup = config.get(\"use_mup\", False)\n",
    "        if embedding is not None:\n",
    "            if use_mup:\n",
    "                self.linear = MuSharedReadout(embedding.weight, bias=False)\n",
    "            else:\n",
    "                self.linear = nn.Linear(config[\"d_model\"], config[\"vocab_size\"])\n",
    "                self.linear.weight = embedding.weight\n",
    "        else:\n",
    "            if use_mup:\n",
    "                self.linear = MuReadout(config[\"d_model\"], config[\"vocab_size\"])\n",
    "            else:\n",
    "                self.linear = nn.Linear(config[\"d_model\"], config[\"vocab_size\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the Diffusion Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class TransformerDenoiseModel(nn.Module):\n",
    "    def __init__(self, feature_size, num_layers=6, nhead=8, dim_feedforward=2048):\n",
    "        super().__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.positional_encoding = PositionalEncoding(feature_size)\n",
    "        encoder_layers = TransformerEncoderLayer(feature_size, nhead, dim_feedforward, dropout=0.1)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc_out = nn.Linear(feature_size, feature_size)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # print(x.size())\n",
    "        # print(self.positional_encoding(t, x.size(0)).size())\n",
    "        x = x.to(device)\n",
    "        x = x + self.positional_encoding(t, x.size(0), x.size(1)).to(device)\n",
    "        x = self.transformer_encoder(x)\n",
    "        return self.fc_out(x)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, t, batch_size, feature_size):\n",
    "        pos_emb = self.pe[t, :].expand(batch_size, feature_size, -1)\n",
    "        return nn.Sigmoid()(pos_emb, dim=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class Diffusion(nn.Module):\n",
    "    def __init__(self, model, num_columns, emb_dim, n_times=1000, beta_minmax=[1e-4, 2e-2], device='cuda'):\n",
    "\n",
    "        super(Diffusion, self).__init__()\n",
    "\n",
    "        self.n_times = n_times\n",
    "        self.num_columns = num_columns\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        # define linear variance schedule(betas)\n",
    "        beta_1, beta_T = beta_minmax\n",
    "        betas = torch.linspace(start=beta_1, end=beta_T, steps=n_times).to(device)  # follows DDPM paper\n",
    "        self.sqrt_betas = torch.sqrt(betas)\n",
    "\n",
    "        # define alpha for forward diffusion kernel\n",
    "        self.alphas = 1 - betas\n",
    "        self.sqrt_alphas = torch.sqrt(self.alphas)\n",
    "        alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "        self.sqrt_one_minus_alpha_bars = torch.sqrt(1 - alpha_bars)\n",
    "        self.sqrt_alpha_bars = torch.sqrt(alpha_bars)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def extract(self, a, t, x_shape):\n",
    "        \"\"\"\n",
    "            from lucidrains' implementation\n",
    "                https://github.com/lucidrains/denoising-diffusion-pytorch/blob/beb2f2d8dd9b4f2bd5be4719f37082fe061ee450/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py#L376\n",
    "        \"\"\"\n",
    "        b, *_ = t.shape\n",
    "        out = a.gather(-1, t)\n",
    "        return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "    def scale_to_minus_one_to_one(self, x):\n",
    "        # according to the DDPMs paper, normalization seems to be crucial to train reverse process network\n",
    "        return x * 2 - 1\n",
    "\n",
    "    def reverse_scale_to_zero_to_one(self, x):\n",
    "        return (x + 1) * 0.5\n",
    "\n",
    "    def make_noisy(self, x_zeros, t):\n",
    "        # perturb x_0 into x_t (i.e., take x_0 samples into forward diffusion kernels)\n",
    "        epsilon = torch.randn_like(x_zeros).to(self.device)\n",
    "\n",
    "        sqrt_alpha_bar = self.extract(self.sqrt_alpha_bars, t, x_zeros.shape)\n",
    "        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars, t, x_zeros.shape)\n",
    "\n",
    "        # Let's make noisy sample!: i.e., Forward process with fixed variance schedule\n",
    "        #      i.e., sqrt(alpha_bar_t) * x_zero + sqrt(1-alpha_bar_t) * epsilon\n",
    "        noisy_sample = x_zeros * sqrt_alpha_bar + epsilon * sqrt_one_minus_alpha_bar\n",
    "\n",
    "        return noisy_sample.detach(), epsilon\n",
    "\n",
    "    def denoise_back_to_x0(self, noisy_sample, predicted_epsilon, t):\n",
    "        sqrt_alpha_bar = self.extract(self.sqrt_alpha_bars, t, noisy_sample.shape)\n",
    "        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars, t, noisy_sample.shape)\n",
    "\n",
    "        # denoise at time t, utilizing predicted noise\n",
    "        x_0 = 1 / sqrt_alpha_bar * (noisy_sample - sqrt_one_minus_alpha_bar * predicted_epsilon)\n",
    "        return x_0\n",
    "\n",
    "    def forward(self, x_zeros):\n",
    "        x_zeros = self.scale_to_minus_one_to_one(x_zeros)\n",
    "\n",
    "        B, _, _ = x_zeros.shape\n",
    "\n",
    "        # (1) randomly choose diffusion time-step\n",
    "        t = torch.randint(low=0, high=self.n_times, size=(B,)).long().to(self.device)\n",
    "\n",
    "        # (2) forward diffusion process: perturb x_zeros with fixed variance schedule\n",
    "        perturbed_images, epsilon = self.make_noisy(x_zeros, t)\n",
    "\n",
    "        # (3) predict epsilon(noise) given perturbed data at diffusion-timestep t.\n",
    "        pred_epsilon = self.model(perturbed_images, t)\n",
    "\n",
    "        return perturbed_images, epsilon, pred_epsilon, t\n",
    "\n",
    "    def denoise_at_t(self, x_t, timestep, t):\n",
    "        B, _, _ = x_t.shape\n",
    "        if t > 1:\n",
    "            z = torch.randn_like(x_t).to(self.device)\n",
    "        else:\n",
    "            z = torch.zeros_like(x_t).to(self.device)\n",
    "\n",
    "        # at inference, we use predicted noise(epsilon) to restore perturbed data sample.\n",
    "        epsilon_pred = self.model(x_t, timestep)\n",
    "\n",
    "        alpha = self.extract(self.alphas, timestep, x_t.shape)\n",
    "        sqrt_alpha = self.extract(self.sqrt_alphas, timestep, x_t.shape)\n",
    "        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars, timestep, x_t.shape)\n",
    "        sqrt_beta = self.extract(self.sqrt_betas, timestep, x_t.shape)\n",
    "\n",
    "        # denoise at time t, utilizing predicted noise\n",
    "        x_t_minus_1 = 1 / sqrt_alpha * (x_t - (1 - alpha) / sqrt_one_minus_alpha_bar * epsilon_pred) + sqrt_beta * z\n",
    "\n",
    "        return x_t_minus_1.clamp(-1., 1)\n",
    "\n",
    "    def predict(self, x, mask):\n",
    "        # start from random noise vector, x_0 (for simplicity, x_T declared as x_t instead of x_T)\n",
    "        x_t = torch.randn((x.size(0), self.num_columns, self.emb_dim)).to(self.device)\n",
    "        # Denoise\n",
    "        for t in range(self.n_times - 1, -1, -1):\n",
    "            for j in range(5): ## Harmonization\n",
    "                timestep = torch.tensor([t]).repeat_interleave(x.size(0), dim=0).long().to(self.device)\n",
    "                x_t_1_unknown = self.denoise_at_t(x_t, timestep, t)\n",
    "                if t > 0:\n",
    "                    x_t_1_known, epsilon = self.make_noisy(x, timestep - 1)\n",
    "                else:\n",
    "                    x_t_1_known = x\n",
    "                    epsilon = torch.zeros_like(x_t_1_known[:, :self.n_features]).to(self.device)\n",
    "                x_t_1 = torch.zeros_like(x_t_1).to(self.device)\n",
    "                for i, m in enumerate(mask):\n",
    "                    if m.item():\n",
    "                        x_t_1[:, i] = x_t_1_known[:, i]\n",
    "                    else:\n",
    "                        x_t_1[:, i] = x_t_1_unknown[:, i]\n",
    "                if j < 4 and t > 0:\n",
    "                    # Add noise for one step\n",
    "                    x_t = self.sqrt_alphas[t] * x_t_1 + self.sqrt_betas[t] * epsilon.to(self.device)\n",
    "                else:\n",
    "                    x_t = x_t_1\n",
    "\n",
    "        x_0 = self.reverse_scale_to_zero_to_one(x_t) # reverse normalization\n",
    "        # x_0 = x_t\n",
    "        return x_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset DATASET] [--d_model D_MODEL]\n",
      "                             [--d_ff_mult D_FF_MULT] [--nhead NHEAD]\n",
      "                             [--num_layers NUM_LAYERS]\n",
      "                             [--field_encoder_layers FIELD_ENCODER_LAYERS]\n",
      "                             [--field_decoder_layers FIELD_DECODER_LAYERS]\n",
      "                             [--num_decoder_mixtures NUM_DECODER_MIXTURES]\n",
      "                             [--num_emb NUM_EMB]\n",
      "                             [--tie_numerical_embeddings TIE_NUMERICAL_EMBEDDINGS]\n",
      "                             [--tie_numerical_decoders TIE_NUMERICAL_DECODERS]\n",
      "                             [--num_categorical_decoder_experts NUM_CATEGORICAL_DECODER_EXPERTS]\n",
      "                             [--condition_decoders_on_hierarchy CONDITION_DECODERS_ON_HIERARCHY]\n",
      "                             [--tie_mask_embeddings TIE_MASK_EMBEDDINGS]\n",
      "                             [--epochs EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                             [--lr LR] [--weight_decay WEIGHT_DECAY]\n",
      "                             [--dropout DROPOUT]\n",
      "                             [--train_mask_rate TRAIN_MASK_RATE]\n",
      "                             [--eval_mask_rate EVAL_MASK_RATE] [--wandb WANDB]\n",
      "                             [--tags TAGS [TAGS ...]] [--device DEVICE]\n",
      "                             [--seed SEED] [--rootdir ROOTDIR] [--ckpt CKPT]\n",
      "                             [--model MODEL] [--exp_name EXP_NAME]\n",
      "                             [--log_params LOG_PARAMS]\n",
      "                             [--float_precision FLOAT_PRECISION]\n",
      "                             [--never_mask NEVER_MASK [NEVER_MASK ...]]\n",
      "                             [--text_model TEXT_MODEL]\n",
      "                             [--tie_embeddings TIE_EMBEDDINGS]\n",
      "                             [--tokenizer TOKENIZER]\n",
      "                             [--text_decoder_layers TEXT_DECODER_LAYERS]\n",
      "                             [--text_encoder_layers TEXT_ENCODER_LAYERS]\n",
      "                             [--encoder_readout ENCODER_READOUT] [--use_mup]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/admin1/.local/share/jupyter/runtime/kernel-e952fa9e-3d85-46c5-baba-bcd16e6e164f.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/gaussian-disk/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from data.dataloader import DateDataset, TestDateDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from config import defaults_customLM as config\n",
    "from utils import parse_args\n",
    "# Load JSON data\n",
    "with open(\"/home/admin1/Documents/Gaussian-Names-Model/data/date_dataset.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert JSON data to DataFrame\n",
    "df = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "config = parse_args(config)\n",
    "# Create dataset and dataloader\n",
    "dataset = DateDataset(df, config)\n",
    "test_dataset = TestDateDataset(df, config, size=5)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "model = TransformerDenoiseModel(feature_size=config[\"d_model\"]).to(device)\n",
    "diffusion = Diffusion(model, device=device).to(device)\n",
    "text_model = TextModule(config)\n",
    "print(f\"Model has {(sum(p.numel() for p in model.parameters() if p.requires_grad)) + (sum(p.numel() for p in text_model.parameters() if p.requires_grad))} trainable parameters\")\n",
    "optimizer = torch.optim.Adam(nn.ModuleList([text_model, diffusion]).parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs = 50\n",
    "\n",
    "print(\"Start training DDPMs...\")\n",
    "model.train()\n",
    "text_model.train()\n",
    "step = 0\n",
    "best_test_loss = float(\"inf\")\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    model.train()\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    train_loss = 0\n",
    "    for x in loop:\n",
    "        # Encode the text\n",
    "        x = x.to(config[\"device\"])  # (batch_size, num_of_properties, max_len)\n",
    "        x0 = torch.zeros(x.shape[0], x.shape[1], config[\"d_model\"]).to(config[\"device\"])\n",
    "        for j in range(x.shape[1]):\n",
    "            output = text_model.encoder(\n",
    "                x[:, j, :], padding_mask=(x[:, j, :] != 0).float()\n",
    "            )  # (batch_size, max_len, d_model)\n",
    "            x0[:, j] = output[:, 0]  # (batch_size, d_model)\n",
    "        x0 = x0.to(device)\n",
    "        # Perturb the data\n",
    "        x_t, epsilon, pred_epsilon, t = diffusion(x0)\n",
    "        # Use the predicted noise to predict the original data\n",
    "        x0_pred = diffusion.denoise_back_to_x0(x_t, pred_epsilon, t)\n",
    "        # Generate the text based on the reconstructed data\n",
    "        prediction = []\n",
    "        loss = 0\n",
    "        for j in range(x0_pred.shape[1]):\n",
    "            target = text_model._shift_right(x[:, j, :])  # (batch_size, max_len)\n",
    "            output = text_model.decoder(target, x0[:, j].unsqueeze(1))  # (batch_size, max_len, vocab_size)\n",
    "            output = output.unsqueeze(1)\n",
    "            prediction.append(output)\n",
    "        prediction = torch.cat(prediction, dim=1)  # (batch_size, num_of_properties, max_len, vocab_size)\n",
    "        # print(\"predcition shape:\", prediction.shape)\n",
    "        # print(\"x shape:\", x.shape)\n",
    "        loss = loss_fn(prediction.view(-1, prediction.size(-1)), x.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loop.set_description(f\"Epoch [{epoch + 1}/{config['epochs']}]\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        train_loss += loss.item()\n",
    "        if step % 1000 == 0:\n",
    "            print()\n",
    "            print(f\"Training Epoch: {epoch + 1}, Step: {step}\")\n",
    "            print(\"Prediction:\", dataset.tokenizer.batch_decode(torch.argmax(prediction[0], dim=-1), skip_special_tokens=True))\n",
    "            print(\"Ground truth:\", dataset.tokenizer.batch_decode(x[0], skip_special_tokens=True))\n",
    "        step += 1\n",
    "    print(f\"Epoch [{epoch + 1}/{config['epochs']}], Loss: {train_loss / len(dataloader)}\")\n",
    "    # scheduler.step()\n",
    "    test_loss = 0\n",
    "    model.eval()\n",
    "    test_count = 0\n",
    "    for d in test_dataloader:\n",
    "        x = d[\"target\"]\n",
    "        mask = d[\"mask\"]\n",
    "        mask = mask.squeeze(0)\n",
    "        x = x.to(config[\"device\"])  # (batch_size, num_of_properties, max_len)\n",
    "        # Encode the text\n",
    "        x_label = torch.zeros(x.shape[0], x.shape[1], config[\"d_model\"]).to(config[\"device\"])\n",
    "        for j in range(x.shape[1]):\n",
    "            output = text_model.encoder(\n",
    "                x[:, j, :], padding_mask=(x[:, j, :] != 0).float()\n",
    "            )  # (batch_size, max_len, d_model)\n",
    "            if config[\"text_model\"] == \"custom\":\n",
    "                x_label[:, j] = output[:, 0]  # (batch_size, d_model)\n",
    "            else:\n",
    "                x_label[:, j] = output.last_hidden_state[:, 0]  # (batch_size, d_model)\n",
    "\n",
    "        # Denoise\n",
    "        # Random prior\n",
    "        sample = diffusion.predict(x_label, mask)\n",
    "\n",
    "        # Decode generated back to text\n",
    "        max_len = x.shape[-1]\n",
    "        temp = 0.0\n",
    "        sample = sample.float()\n",
    "        prediction = []\n",
    "        for j in range(sample.shape[1]):\n",
    "            # make initial input\n",
    "            batch_size = sample.shape[0]\n",
    "            current_input = torch.full(\n",
    "                (batch_size, 1),\n",
    "                config[\"categorical_pad_token_id\"],\n",
    "                device=sample.device,\n",
    "            )\n",
    "            for i in range(max_len):\n",
    "                pred = text_model.decoder(\n",
    "                    input_ids=current_input,\n",
    "                    encoder_hidden_states=sample[:, j, :].unsqueeze(1),\n",
    "                )\n",
    "                pred = pred[:, -1, :]\n",
    "                if temp == 0:\n",
    "                    current_input = torch.cat(\n",
    "                        (current_input, pred.argmax(-1, keepdim=True)), -1\n",
    "                    )\n",
    "                else:\n",
    "                    probs = torch.softmax(pred / temp, dim=-1)\n",
    "                    current_input = torch.cat(\n",
    "                        (current_input, torch.multinomial(probs, 1)), -1\n",
    "                    )\n",
    "            output = current_input[:, 1:]\n",
    "            output = output.unsqueeze(1)\n",
    "            prediction.append(output)\n",
    "        prediction = torch.cat(prediction, dim=1)  # (batch_size, num_of_properties, max_len, vocab_size)\n",
    "        # only calculate loss on the masked tokens\n",
    "        mask = mask.unsqueeze(0)\n",
    "        mask_prediction = prediction[mask == 0].view(-1, prediction.size(-1))\n",
    "        mask_x = x[mask == 0].view(-1)\n",
    "        # loss = loss_fn(mask_prediction, mask_x)\n",
    "        # test_loss += loss.item()\n",
    "        test_count += 1\n",
    "        if test_count % 1 == 0:\n",
    "            print()\n",
    "            print(f\"Test Epoch: {epoch + 1}\")\n",
    "            print(\"Prediction:\", dataset.tokenizer.batch_decode(prediction[0], skip_special_tokens=True))\n",
    "            print(\"Mask:\", mask[0])\n",
    "            print(\"Ground truth:\", dataset.tokenizer.batch_decode(x[0], skip_special_tokens=True))\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        print(\"Saving model... at epoch\", epoch + 1)\n",
    "        torch.save(model.state_dict(), f\"./saved/denoise_best_model.pt\")\n",
    "        torch.save(text_model.state_dict(), f\"./saved/text_best_model.pt\")\n",
    "print(\"Training complete!\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
